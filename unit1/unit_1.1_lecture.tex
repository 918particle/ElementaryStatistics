\documentclass{beamer}
\usetheme{metropolis}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{tcolorbox}
\title{Elementary Statistics: Math 080}
\author{Jordan Hanson}
\institute{Whittier College Department of Physics and Astronomy}

\begin{document}
\maketitle

\section{Summary}

\begin{frame}{Summary}
\begin{enumerate}
\item Topics from Chapter 4: 4.1 - 4.4
\begin{itemize}
\item Discrete random variables
\item Expectation values and standard deviations
\item The binomial distribution
\item The geometric distribution
\end{itemize}
\item Topics from Chapter 6: 6.1 - 6.4
\begin{enumerate}
\item The normal and standard normal distributions
\item Using normal distributions
\end{enumerate}
\end{enumerate}
\end{frame}

\section{Discrete Random Variables}

\begin{frame}{Discrete Random Variables}
A \alert{discrete random variable} is a property of data that can be counted with integers. \\ \vspace{0.5cm} Examples:
\begin{itemize}
\item Times a baby eats per day
\item Number of students in a class
\item The number of wins a team has in a season
\item \textit{The number of calories we ate yesterday} - We may think of this as discrete if we have to round to the nearest calorie
\end{itemize}
\end{frame}

\begin{frame}{Discrete Random Variables}
\small
\begin{table}
\centering
\begin{tabular}{| c | c | c | c | c |}
\hline
\hline
Bin & $n$ & $P(x)$ & $x*P(x)$ & $(x-\mu)^2 P(x)$ \\ \hline
0-10k & 13 & & & \\ \hline
10-20k & 15 & & & \\ \hline
20-30k & 20 & & & \\ \hline
30-40k & 11 & & & \\ \hline
40-50k & 9 & & & \\ \hline
50-60k & 9 & & & \\ \hline
60-70k & 6 & & & \\ \hline
70-80k & 7 & & & \\ \hline
80-90k & 5 & & & \\ \hline
90-100k & 3 & & & \\ \hline
100k+ & 2 & & & \\ \hline
\textbf{Totals} & 100 & & & \\ \hline
\hline
\end{tabular}
\caption{\label{tab:wages} Wage data for 100 Los Angeles County workers.}
\end{table}
\end{frame}

\begin{frame}{Discrete Random Variables}
\small
$P(X)$ is a \alert{\textbf{Probability distribution function}} of a discrete random variable.
PDFs are tools for answering questions like:
\begin{enumerate}
\item What is the probability that a random individual in LA County earns yearly wages in the top 5 categories of Tab. \ref{tab:wages}?
\item What is the probability that a random individual in LA County earns yearly wages in the bottom 5 categories of Tab. \ref{tab:wages}?
\item What is the \textit{expectation value} of Tab. \ref{tab:wages}?
\item What is the \textit{standard deviation} of Tab. \ref{tab:wages}?
\end{enumerate}
\end{frame}

\begin{frame}{Discrete Random Variables}
\small
\begin{table}
\centering
\begin{tabular}{| c | c | c | c | c |}
\hline
\hline
Bin & $n$ & $P(x)$ & $x*P(x)$ & $(x-\mu)^2 P(x)$ \\ \hline
0 & 45 & & & \\ \hline
1 & 190 & & & \\ \hline
2 & 410 & & & \\ \hline
3 & 220 & & & \\ \hline
4 & 80 & & & \\ \hline
5 & 55 & & & \\ \hline
\textbf{Totals} & 1000 & & & \\ \hline
\hline
\end{tabular}
\caption{\label{tab:cars} Number of cars owned by 1,000 California citizens.}
\end{table}
\end{frame}

\begin{frame}{Discrete Random Variables}
\small
Consider Tab. \ref{tab:cars} above.
\begin{enumerate}
\item What is the probability that a random Californian has 2 or fewer cars, according to Tab. \ref{tab:cars}?
\item Suppose a random Californian owns 4 cars.  How many standard deviations above the mean is this, according to Tab. \ref{tab:cars}?
\end{enumerate}
\end{frame}

\begin{frame}{Discrete Random Variables}
\small
\begin{table}
\centering
\begin{tabular}{| c | c | c | c | c |}
\hline
\hline
Bin & $n$ & $P(x)$ & $x*P(x)$ & $(x-\mu)^2 P(x)$ \\ \hline
200-300k & 110 & & & \\ \hline
300-400k & 130 & & & \\ \hline
400-500k & 140 & & & \\ \hline
500-750k & 270 & & & \\ \hline
750-1000k & 100 & & & \\ \hline
1000k+ & 250 & & & \\ \hline
\textbf{Totals} & 1000 & & & \\ \hline
\hline
\end{tabular}
\caption{\label{tab:homes} Values of 1,000 residential properties in Los Angeles County.}
\end{table}
\end{frame}

\begin{frame}{Discrete Random Variables}
\small
Consider Tab. \ref{tab:homes} and Tab. \ref{tab:wages} above.
\begin{enumerate}
\item Consider the wage distribution of Tab. \ref{tab:wages}, and consider the home value distribution of Tab. \ref{tab:homes}.  What is the average home value divided by the average yearly wage?  What statistical fact does this reveal?
\item Typically, residents of California devote 30-40 percent of their budget to housing.  Take 35 percent as a good estimate, and apply it to the prior calculation.  How many years must someone work for the average wage to purchase an average home?
\item For more data and interesting figures, see \url{https://datausa.io/profile/geo/los-angeles-county-ca}
\end{enumerate}
\end{frame}

\begin{frame}{Discrete Random Variables}
\begin{figure}
\centering
\includegraphics[width=0.9\textwidth]{figures/homes.png}
\caption{\label{fig:homes2} The effect of the FHA on home ownership in California across several decades.}
\end{figure}
\end{frame}

\section{The Binomial Distribution}

\begin{frame}{The Binomial Distribution}
Suppose we suspect a discrete random variable data set is binomially-distributed.  The mean is $\mu = 2.1$ and the standard deviation is $\sigma = 1.0$.  Suppose this data had 10 trials.  Independently, someone tells us that the probability of a trial being successful in a similar experiment was 0.4.  Is this data binomially-distributed?
\begin{itemize}
\item A: Yes, the mean follows $\mu = N p$ within one standard deviation.
\item B: No, the mean does not follow $\mu = N p$ within one standard deviation.
\item C: Yes, the mean implies a probability of success of 0.4.
\item D: No, the standard deviation is too large to make the determination.
\end{itemize}
\end{frame}

\begin{frame}{The Binomial Distribution}
Suppose we are working with a biological experiment to predict the behavior of a small aquatic creature when its environment is inside a large magnetic field.  The creature can either choose to go left (in the direction of the compass) or right (opposite to the compass).  We conduct 10 trials on the same individual, and then repeat on 10 different individuals.  How would you determine if the creatures are following the magnetic field?
\begin{itemize}
\item A: Count the number of times in all runs, all trials, that the individuals go left.  If it is more than half the time, $p>50\%$.
\item B: Count the number of times per run that the individuals go left.  Calculate the expectation value of those frequencies, and derive $p$.
\end{itemize}
\end{frame}

\section{Probability Distributions Can Be Continuous}

\begin{frame}{Continuous Random Variables}
Suppose instead of \textit{counting trials}, we measure a number.  Identify below: discrete random variable or continuous random variable?
\begin{enumerate}
\item Measuring the heights of a sample of people
\item Measuring the number of home runs a baseball player earns per season
\item Measuring the number of hands a poker player wins per game won
\item Measuring the wind speed on the top of a mountain
\end{enumerate}
\end{frame}

\begin{frame}{Continuous Random Variables}
\begin{figure}
\centering
\includegraphics[width=8cm]{figures/uniform.png}
\caption{\label{fig:uniform} A uniform PDF of a \textit{continuous random variable.}}
\end{figure}
\begin{itemize}
\item How do we \textit{normalize} the frequencies?
\item How do we calculate probabilites?
\item What are the expectation value and standard deviation?
\end{itemize}
\end{frame}

\begin{frame}{Continuous Random Variables}
\begin{figure}
\centering
\includegraphics[width=8cm]{figures/uniform.png}
\caption{\label{fig:uniforma} A uniform PDF of a \textit{continuous random variable.}}
\end{figure}
\begin{itemize}
\item Normalization: $1/(b-a)$
\item Probability that $x_1 < x < x_2$? $(x_2 - x_1)/(b - a)$
\item $E[x] = \mu = (b+a)/2$, $\sqrt{Var[x]} = \sigma = \sqrt{(b-a)^2/12}$
\end{itemize}
\end{frame}

\begin{frame}{Continuous Random Variables}
\begin{figure}
\centering
\includegraphics[width=8cm]{figures/exp.png}
\caption{\label{fig:exp} An exponential PDF of a \textit{continuous random variable.}}
\end{figure}
\end{frame}

\begin{frame}{Continuous Random Variables}
\begin{figure}
\centering
\includegraphics[width=8cm]{figures/normal.png}
\caption{\label{fig:norm} A normal distribution PDF of a \textit{continuous random variable.}}
\end{figure}
\end{frame}

\begin{frame}{Continuous Random Variables}
Suppose we record the volume of milk a baby drinks per feeding when between the ages of 0-3 months.  The volumes are \textbf{\alert{uniformly}} distributed between 3.0 and 4.0 ounces per feeding.  We record 100 measurements.
\begin{itemize}
\item What is the normalization?  Or, graph the PDF.
\item What is the mean volume?
\item What is the standard deviation?
\item What is the probability of finding a measurement in the set between 3.2 and 3.5 ounces per feeding?
\end{itemize}
\end{frame}

\begin{frame}{Continuous Random Variables}
Suppose we record the volume of milk a baby drinks per feeding when between the ages of 0-3 months.  The volumes are \textbf{\alert{uniformly}} distributed between 3.0 and 4.0 ounces per feeding.  We record 100 measurements.
\begin{itemize}
\item What are the quartiles of the data?
\item What is the 90th percentile of the data?
\end{itemize}
\end{frame}

\section{Interactive Questions}

\begin{frame}{Interactive Questions}
Suppose we are looking at a distribution (histogram/PDF) of a baseball team's batting average (probability a player gets a hit), and it is uniformly distributed.  The lowest value is 0.200 and the highest is 0.400.  What is the mean of the distribution?
\begin{itemize}
\item A: 0.200
\item B: 0.300
\item C: 0.400
\item D: 0.350
\end{itemize}
\end{frame}

\begin{frame}{Interactive Questions}
Suppose we are looking at a distribution (histogram/PDF) of a baseball team's batting average (probability a player gets a hit), and it is uniformly distributed.  The lowest value is 0.200 and the highest is 0.400.  What is the median?
\begin{itemize}
\item A: 0.200
\item B: 0.300
\item C: 0.400
\item D: 0.350
\end{itemize}
\end{frame}

\begin{frame}{Interactive Questions}
Suppose we are looking at a distribution (histogram/PDF) of a baseball team's batting average (probability a player gets a hit), and it is uniformly distributed.  The lowest value is 0.200 and the highest is 0.400.  What is the probability of being between 0.300 and 0.350?
\begin{itemize}
\item A: 10 percent
\item B: 15 percent
\item C: 25 percent
\item D: 50 percent
\end{itemize}
\end{frame}

\section{Statistics and Probability: The Normal Distribution}

\begin{frame}[fragile]{Statistics and Probability: The Normal Distribution}
The \textit{mean}, $\mu$, and \textit{standard deviation}, $\sigma$, of a data set $\lbrace x_i \rbrace$ are defined as
\begin{align}
\mu &= \frac{1}{N}\sum_{i=1}^N x_i \\
\sigma^2 &= \frac{1}{N-1}\sum_{i=1}^N\left(x_i-\mu\right)^2
\end{align}
Octave commands:
\begin{verbatim}
x = randn(100,1);
mean(x)
std(x)
\end{verbatim}
\end{frame}

\begin{frame}[fragile]{Statistics and Probability: The Normal Distribution}
One nice theorem: \textit{The variance is the average of the squares minus the square of the average.}  Let $\langle x \rangle$ represent the average of the quantity or expression $x$.  We have
\begin{equation}
\sigma_x^2 = \langle x^2 \rangle - \langle x \rangle^2
\end{equation}
Proof: observe on board.
\end{frame}

\begin{frame}[fragile]{Statistics and Probability: The Normal Distribution}
\small
\textbf{Note}: There is a distinction between the \textit{process or signal process} and the \textit{the data}.  Just because the data has a given $\mu$ and $\sigma$ does not imply that the signal process has or will continue to have the exact same values of $\mu$ and $\sigma$.  The underlying process could be \textit{non-stationary}.
\begin{figure}
\centering
\includegraphics[width=0.9\textwidth]{figures/non_stationary.png}
\caption{\label{fig:non_stationary} Signal processes in (a) and (b) are considered \alert{non-stationary} because one or both of $\mu$ and $\sigma$ depend on time.}
\end{figure}
\end{frame}

\begin{frame}[fragile]{Statistics and Probability: The Normal Distribution}
\small
\textbf{A histogram} is an object that represents the frequency\footnote{Careful: the word frequency refers to the number of occurences in the data, not a sinusoidal frequency.} of particular values in a signal.  For example, below is a histogram of 256,000 numbers drawn from a probability distribution:
\begin{figure}
\centering
\includegraphics[width=0.45\textwidth]{figures/hist.png}
\caption{\label{fig:hist} The histogram contains counts versus sample values.}
\end{figure}
\end{frame}

\begin{frame}[fragile]{Statistics and Probability: The Normal Distribution}
The following octave code should reproduce something like Fig. \ref{fig:hist} from the textbook:
\begin{verbatim}
x = randn(256000,1)*10.0+130.0;
[b,a] = hist(x,100);
plot(a,b,'o');
\end{verbatim}
The function \textit{randn(N,M)} draws $N \times M$ numbers from a normal distribution and returns them in the size the user desires.  The function \textit{hist(x,N)} creates $N$ bins and sorts the data $x_i$ into them.
\end{frame}

\begin{frame}[fragile]{Statistics and Probability: The Normal Distribution}
\small
For data that is appropriately stationary, we can use histograms to estimate $\mu$ and $\sigma$ faster, since we only have to loop over bins rather than every data sample.  Let $H_i$ represent the counts in a given bin, and $i$ represent the bin sample.  We have:
\begin{align}
\mu &= \frac{1}{N}\sum_{i=1}^{M}i H_i \label{eq:histmean} \\
\sigma^{2} &= \frac{1}{N-1}\sum_{i=1}^M \left(i-\mu\right)^2 H_i \label{eq:histvar}
\end{align}
To obtain the mean in signal \textit{amplitude}, you'll have to convert bin number to amplitude.
\end{frame}

\begin{frame}[fragile]{Statistics and Probability: The Normal Distribution}
\small
\begin{table}
\begin{tabular}{c}
3.1 \\
-0.03 \\
1.2 \\
0.2 \\
-0.7 \\
-1.45 \\
2.2 \\
-0.05 \\
0.93 \\
0.21 
\end{tabular}
\caption{\label{tab:hist} Using Eq. \ref{eq:histmean} and \ref{eq:histvar}, find estimates of $\mu$ and $\sigma$ for this data.}
\end{table}
\begin{verbatim}
x = [...];
[b,a] = hist(x,4); %(How many bins?)
\end{verbatim}
\end{frame}

\begin{frame}[fragile]{Statistics and Probability: The Normal Distribution}
\small
Some vocabulary:
\begin{itemize}
\item \textbf{normalization} - Total probability is 1.0.  For pdf - the integral from $[-\infty,\infty]$ is 1.0.  For pmf - the sum from $[-\infty,\infty]$ is 1.0.
\item \textbf{pmf} - Probability mass function: A \textit{normalized continuous function} that gives the probability of a value, given the value.
\item \textbf{histogram} - Histograms are an attempted measurement of the pmf by breaking the data into discrete bins.  Histograms can be \textit{normalized} as well.
\item \textbf{pdf} - Probability density function: A \textit{normalized continuous function} that gives the probability density of a value, given the value.  Integrating the \textit{normalized} pdf between two values gives the probability of observing data between the given values.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Statistics and Probability: The Normal Distribution}
\begin{figure}
\centering
\includegraphics[width=0.7\textwidth]{figures/squarepdf.png}
\caption{\label{fig:squarepdf} The square-wave signal spends equal time at 0.0 and 1.0, and the probability density function reflects that.}
\end{figure}
\end{frame}

\begin{frame}[fragile]{Statistics and Probability: The Normal Distribution}
\begin{figure}
\centering
\includegraphics[width=0.7\textwidth]{figures/trianglepdf.png}
\caption{\label{fig:trianglepdf} The triangle-wave signal spends equal time at all values \textit{between} 0.0 and 1.0, and the probability density function reflects that.}
\end{figure}
\end{frame}

\begin{frame}[fragile]{Statistics and Probability: The Normal Distribution}
\begin{figure}
\centering
\includegraphics[width=0.7\textwidth]{figures/randnpdf.png}
\caption{\label{fig:randnpdf} The random noise \textit{usually} spends time near 0.0, but rarely it fluctuates to larger values.}
\end{figure}
\end{frame}

\begin{frame}{Normal distribution}
\textbf{Normally distributed} data decreases in probability at a rate that is proportional (1) to the \textit{distance from the mean}, and that is proportional (2) to the \textit{probability itself.}
\begin{figure}
\centering
\includegraphics[width=0.5\textwidth,trim=0cm 6cm 0cm 6cm,clip=true]{figures/hist_binCount.pdf}
\caption{\label{fig:hist1} Normally distributed data counts decrease as measured further from the mean for \textit{two reasons.}}
\end{figure}
\end{frame}

\begin{frame}{Normal distribution}
\begin{tcolorbox}[colback=white,colframe=red!40!blue,title=Normal Distribution PDF]
\alert{Let $p(x)$ be the PDF of normally distributed data $x$ with mean $\mu$. In order to obey conditions (1) and (2), the function $p(x)$ must be described by the following differential equation, where $k$ is some constant.}
\alert{\begin{equation}
\frac{dp}{dx} = -k(x-\mu)p(x) \label{eq:normDiffeq}
\end{equation}}
\end{tcolorbox}
\end{frame}

\begin{frame}{Normal distribution}
Rearranging Eq. \ref{eq:normDiffeq}, we have
\begin{equation}
\frac{dp}{p} = -k(x-\mu) dx
\end{equation}
Integrating both sides gives
\begin{equation}
\ln(p) = -\frac{1}{2}k(x-\mu)^2+C_0
\end{equation}
Exponentiating,
\begin{equation}
p(x) = C_1 \exp\left(-\frac{1}{2}k(x-\mu)^2\right) \label{eq:normDiffeq2}
\end{equation}
Ensuring that the PDF is \textit{normalized} requires
\begin{equation}
\int_{-\infty}^{\infty} p(x) dx = 1
\end{equation}
\end{frame}

\begin{frame}{Normal distribution}
But how do we integrate Eq. \ref{eq:normDiffeq2}?  First, a change of variables.  Let $s = \sqrt{k/2}(x-\mu)$, so $ds = \sqrt{k/2}dx$.  Then, we have
\begin{equation}
C_1 \sqrt{\frac{2}{k}} \int_{-\infty}^{\infty} \exp(-s^2) ds = 1
\end{equation}
Squaring both sides, we have
\begin{equation}
C_1^2 \frac{2}{k} \left(\int_{-\infty}^{\infty} \exp(-s^2) ds\right)^2 = 1
\end{equation}
\end{frame}

\begin{frame}{Normal distribution}
Let's pretend the two factors of the integral involve different variables:
\begin{equation}
C_1^2 \frac{2}{k} \left(\int_{-\infty}^{\infty} \exp(-x^2) dx\right)\left(\int_{-\infty}^{\infty} \exp(-y^2) dy\right) = 1
\end{equation}
Now we have
\begin{equation}
C_1^2 \frac{2}{k} \int_{-\infty}^{\infty} \exp(-(x^2+y^2)) dx dy = 1
\end{equation}
Change to polar coordinates ($x^2 + y^2 = r^2$)
\begin{equation}
C_1^2 \frac{2}{k} \int_{0}^{\infty} \int_0^{2\pi} r\exp(-r^2) dr d\phi = 1
\end{equation}
\end{frame}

\begin{frame}{Normal distribution}
One more substitution: $u = r^2$, and $du = 2rdr$:
\begin{equation}
-\frac{C_1^2}{k} \int_0^{\infty}\int_0^{2\pi} \exp(-u) du d\phi = 1
\end{equation}
Solving for $C_1$, we find
\begin{equation}
C_1 = \sqrt{\frac{k}{2\pi}}
\end{equation}
Thus the pdf of normally distributed data is
\begin{equation}
p(x) = \sqrt{\frac{k}{2\pi}} \exp\left(-\frac{1}{2}k(x-\mu)^2\right)
\end{equation}
Let's defined $k = \frac{1}{\sigma_x^2}$ so that it's clear the exponent has the proper ratio of units:
\begin{equation}
\boxed{
p(x) = \sqrt{\frac{1}{2\pi\sigma_x^2}} \exp\left(-\frac{1}{2}\left(\frac{x-\mu}{\sigma_s}\right)^2\right)}
\end{equation}
\end{frame}

\section{Statistics and Probability: Programming with Octave}

\begin{frame}[fragile]{Statistics and Probability: Programming with Octave}
More on the \textit{hist} function in octave\footnote{I hope this works, but if not, it's ok.}
\begin{verbatim}
pkg install -forge io
pkg install -forge statistics
pkg load statistics
pkg help histfit
histfit(randn(1000,1))
histfit(rand(1000,1))
\end{verbatim}
Let's work out the $\sigma$ of a \textit{flat} distribution between $[0,1]$.  What is it for a flat distribution between $[-1,1]$?  (We can derive this by hand as well if we cannot access statistics package).
\end{frame}

\begin{frame}[fragile]{Statistics and Probability: Programming with Octave}
Some interesting notation for normal distributions:
\begin{equation}
N(\mu,\sigma) = \sqrt{\frac{1}{2\pi\sigma^2}} \exp\left(-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2\right)
\end{equation}
Let's write a function \textbf{NGaus.m} that produces the Gaussian probability given $\mu$ and $\sigma$:
\begin{verbatim}
function ret = NGaus(mu,sigma,x)
    ...
endfunction
\end{verbatim}
\end{frame}

\begin{frame}[fragile]{Statistics and Probability: Programming with Octave}
Now let's write a function $NRand$ that sums $N$ uniformly-distributed (flat) random variables $x$:
\begin{verbatim}
function ret = NRand(n)
    ret = sum(rand(n,1));
endfunction
\end{verbatim}
Create a histogram of a few hundred outputs of $NRand$.  What do you notice about the pmf?  Let's plot $NGaus$ on the same axes as the histogram of $NRand$.  How do they compare? \\ \vspace{0.5cm}
We are on our way to producing $N(0,1)$ distributed numbers, and therefore our first \textbf{\alert{noise}} signals...
\end{frame}

\begin{frame}[fragile]{Statistics and Probability: Programming with Octave}
\small
The Box-Muller method for $N(0,1)$ distruted numbers:
\begin{align}
X_1 &= \sqrt{-2\ln(U)}\cos(2\pi V) \\
X_2 &= \sqrt{-2\ln(U)}\sin(2\pi V)
\end{align}
\textbf{Try this in octave...}
More vocabulary:
\begin{itemize}
\item \textbf{cdf} - Cumulative distribution function: Probability that a continuous random variable $X$ is less than some value $x$.  For a given pdf, the cdf $\Phi(X)$ is the integral of the total probability on $[-\infty,x]$.  The derivative of the pdf is related to the pdf via the fundamental theorem of calculus.
\end{itemize}
If the pdf follows $f(x)$, then 
\begin{equation}
\Phi(X\leq x) = \int_{-\infty}^{x} f(x) dx
\end{equation}
\end{frame}

\begin{frame}[fragile]{Statistics and Probability: Programming with Octave}
The cdf of $N(0,1)$ has an expected shape, but can't be expressed with elementary functions.
\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{figures/cdfgaus.png}
\caption{\label{fig:cdfgaus} The cumulative distribution of the normal distribution.  Although we can plot it, it's hard to write.  We will discuss the $erf$ and $erfc$ functions in the near future.}
\end{figure}
\end{frame}

\end{document}